{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:47:14.308692Z","iopub.status.busy":"2023-05-03T13:47:14.308180Z","iopub.status.idle":"2023-05-03T13:47:14.314897Z","shell.execute_reply":"2023-05-03T13:47:14.313692Z","shell.execute_reply.started":"2023-05-03T13:47:14.308642Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","try:\n","    shutil.rmtree(\"generated_images\")\n","    os.mkdir(\"generated_images\")\n","except:\n","    os.mkdir(\"generated_images\")"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-03T13:47:14.316430Z","iopub.status.busy":"2023-05-03T13:47:14.316027Z","iopub.status.idle":"2023-05-03T13:47:23.437187Z","shell.execute_reply":"2023-05-03T13:47:23.435828Z","shell.execute_reply.started":"2023-05-03T13:47:14.316381Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from PIL import Image\n","import numpy as np\n","from MIDIConverter import MIDIConverter\n","from music21 import instrument, note, chord, stream, converter\n","import sys\n","from imageio import imwrite"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:47:23.476429Z","iopub.status.busy":"2023-05-03T13:47:23.476004Z","iopub.status.idle":"2023-05-03T13:55:41.384483Z","shell.execute_reply":"2023-05-03T13:55:41.383031Z","shell.execute_reply.started":"2023-05-03T13:47:23.476392Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2005 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=6, channel=None, data=b'Copyright \\xa9 2004 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2006 by Bernd Krueger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1998 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2007 by Bernd Krueger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2004 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2004 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n"]},{"ename":"UnidentifiedImageError","evalue":"cannot identify image file '/kaggle/input/classical-music-midi/liszt/liz_et6.mid'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/902949408.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcvt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidi2image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcvt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage2midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/3788743886.py\u001b[0m in \u001b[0;36mimage2midi\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimage2midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mim_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3281\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3283\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/kaggle/input/classical-music-midi/liszt/liz_et6.mid'"]}],"source":["# Generating Dataset\n","\n","\n","# os.makedirs(\"generated_images\")\n","cvt = MIDIConverter()\n","parent_path = \"/kaggle/input/classical-music-midi/mozart\"\n","\n","all_files = []\n","\n","for root, dirnames, filenames in os.walk(parent_path):\n","    for j in filenames:\n","        all_files.append(root + \"/\" + j)\n","\n","\n","for fname in all_files:\n","    try:\n","        cvt.midi2image(fname)\n","    except:\n","        pass\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:33.724192Z","iopub.status.busy":"2023-05-03T13:56:33.723781Z","iopub.status.idle":"2023-05-03T13:56:34.442907Z","shell.execute_reply":"2023-05-03T13:56:34.441414Z","shell.execute_reply.started":"2023-05-03T13:56:33.724157Z"},"trusted":true},"outputs":[],"source":["path = '/kaggle/working/generated_images'\n","os.getcwd()\n","img_list = os.listdir(path)\n","\n","\n","def image_data(img_list, path, length):\n","    pixels = []\n","    imgs = []    \n","    for img in img_list:\n","        if \"png\" in img:\n","            # quantized and dithered image\n","            img_arr = Image.open(path+'/'+img, 'r').convert('1') \n","            # normalize the pixel values\n","            pixel = np.array(img_arr.getdata()).astype('float32') / 255.0 \n","            # pad with zeros\n","            pixel = np.pad(pixel, (0, 106 * 106 - pixel.shape[0]), 'constant', constant_values=(0))\n","            # reshaping into 106 to 106\n","            pixels.append(pixel.reshape((106, 106, 1)))\n","            imgs.append(img_arr)\n","    return np.array(pixels), imgs\n","\n","\n","\n","\n","def show_image(pixels):\n","    array = np.array(pixels.reshape(106, 106), dtype=np.uint8)\n","    new_image = Image.fromarray(array)\n","    new_image.show()\n","\n","\n","# pixels, imgs = access_images(img_list, path, 200)\n","pixels, imgs = image_data(img_list, path, 200)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.445679Z","iopub.status.busy":"2023-05-03T13:56:34.445178Z","iopub.status.idle":"2023-05-03T13:56:34.454123Z","shell.execute_reply":"2023-05-03T13:56:34.452709Z","shell.execute_reply.started":"2023-05-03T13:56:34.445640Z"},"trusted":true},"outputs":[],"source":["from numpy import zeros\n","from numpy import ones\n","from numpy import vstack\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras.datasets.mnist import load_data\n","from keras.optimizers import Adam\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten, BatchNormalization\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import Dropout\n","from matplotlib import pyplot\n","from IPython.display import clear_output"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.456153Z","iopub.status.busy":"2023-05-03T13:56:34.455770Z","iopub.status.idle":"2023-05-03T13:56:34.474820Z","shell.execute_reply":"2023-05-03T13:56:34.473408Z","shell.execute_reply.started":"2023-05-03T13:56:34.456114Z"},"trusted":true},"outputs":[],"source":["\n","def define_discriminator(in_shape=(106, 106, 1)):\n","    \n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=in_shape))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(tf.keras.layers.Dropout(0.3))\n","\n","    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same'))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(tf.keras.layers.Dropout(0.3))\n","\n","    model.add(tf.keras.layers.Flatten())\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","    opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy',optimizer=opt, metrics=['accuracy'])\n","    \n","    \n","    return model\n","def define_generator(latent_dim):\n","    model = tf.keras.Sequential()\n","    n_nodes = 128 * 53 * 53\n","    model.add(tf.keras.layers.Dense(n_nodes, input_dim=latent_dim))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(Reshape((53, 53, 128)))\n","    model.add(tf.keras.layers.Dense(1024))\n","    model.add(tf.keras.layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same'))\n","    model.add(tf.keras.layers.Dense(1024))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(tf.keras.layers.Dense(1024))\n","    model.add(tf.keras.layers.Conv2D(1, (7, 7), padding='same', activation='sigmoid'))\n","    return model\n","\n","def define_gan(g_model, d_model):\n","    d_model.trainable = False\n","    model = tf.keras.Sequential()\n","    model.add(g_model)\n","    model.add(d_model)\n","    opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy', optimizer=opt)\n","    return model\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.477724Z","iopub.status.busy":"2023-05-03T13:56:34.477278Z","iopub.status.idle":"2023-05-03T13:56:34.491547Z","shell.execute_reply":"2023-05-03T13:56:34.490018Z","shell.execute_reply.started":"2023-05-03T13:56:34.477685Z"},"trusted":true},"outputs":[],"source":["\n","# Generate Real and Fake Samples to test the discriminator\n","\n","def generate_real_samples(dataset, n_samples):\n","    ix = randint(0, dataset.shape[0], n_samples)\n","    # Return X and y\n","    return dataset[ix], np.ones((n_samples, 1))\n","\n","def generate_fake_samples(g_model, latent_dim, n_samples):\n","    x_input = generate_latent_points(latent_dim, n_samples)\n","    X = g_model.predict(x_input)\n","    y = zeros((n_samples, 1))\n","    return X, y\n","\n","\n","def generate_latent_points(latent_dim, n_samples):\n","    # generate values from normal distribution of shape 106 x 106\n","    x_input = randn(latent_dim * n_samples).reshape(n_samples, latent_dim)\n","    return x_input\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.493837Z","iopub.status.busy":"2023-05-03T13:56:34.493423Z","iopub.status.idle":"2023-05-03T13:56:34.509209Z","shell.execute_reply":"2023-05-03T13:56:34.507803Z","shell.execute_reply.started":"2023-05-03T13:56:34.493737Z"},"trusted":true},"outputs":[],"source":["def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=35, n_batch=10):\n","    bat_per_epo = int(dataset.shape[0] / n_batch)\n","    half_batch = int(n_batch / 2)\n","    n_samples = 100\n","    for i in range(n_epochs):\n","        for j in range(bat_per_epo):\n","            \n","            X_real, y_real = generate_real_samples(dataset, half_batch)\n","            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n","            # get discriminator loss\n","            d_loss, _ = d_model.train_on_batch(X, y)\n","            # get generator loss\n","            g_loss = gan_model.train_on_batch(generate_latent_points(latent_dim, n_batch), ones((n_batch, 1)))\n","            print('>%d, %d/%d, d=%.3f, g=%.3f' %\n","                  (i+1, j+1, bat_per_epo, d_loss, g_loss))\n","        if (i+1) % 10 == 0:\n","            # evaluate performance of discriminator and generator\n","            X_real, y_real = generate_real_samples(dataset, n_samples)\n","\n","            _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n","\n","            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n","            _, acc_fake = d_model.evaluate(X_fake, y_fake, verbose=0)\n","            print('>Accuracy real: %.0f%%, fake: %.0f%%' %\n","                  (acc_real*100, acc_fake*100))\n","            filename = 'generator_model_%03d.h5' % (epoch + 1)\n","            g_model.save(filename)\n","            clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.511788Z","iopub.status.busy":"2023-05-03T13:56:34.510831Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 10s 10s/step\n",">1, 1/43, d=0.795, g=1.662\n","1/1 [==============================] - 9s 9s/step\n"]}],"source":["latent_dim = 100\n","d_model = define_discriminator()\n","g_model = define_generator(latent_dim)\n","gan_model = define_gan(g_model, d_model)\n","train(g_model, d_model, gan_model, np.array(pixels), latent_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.models import load_model\n","from numpy.random import randn\n","from matplotlib import pyplot\n","\n","\n","# Generating the Output\n","\n","def generate_latent_points(latent_dim, n_samples):\n","    x_input = randn(latent_dim * n_samples)\n","    x_input = x_input.reshape(n_samples, latent_dim)\n","    return x_input\n","\n","\n","model = g_model\n","# latent_points = generate_latent_points(latent_dim, 1)\n","# X = g_model.predict(latent_points)\n","# array = np.array(X.reshape(pixel_width, pixel_width), dtype=np.uint8)\n","# array *= 255\n","# new_image = Image.fromarray(array, 'L')\n","# new_image = new_image.save('/kaggle/working/test/composition.png')\n","\n","output_notes = []\n","\n","for i in range(10): \n","    latent_points = generate_latent_points(latent_dim, 1)\n","    X = g_model.predict(latent_points)\n","    array = np.array(X.reshape(pixel_width, pixel_width), dtype=np.uint8)\n","    array *= 255\n","    new_image = Image.fromarray(array, 'L')\n","    new_image = new_image.save('/kaggle/working/test/composition_{}.png'.format(i))\n","    output_notes+=cvt.image2midi('/kaggle/working/test/composition_{}.png'.format(i))\n","    \n","image_path = '/kaggle/working/composition.mid'\n","print(\"Output Notes: \", output_notes)\n","midi_stream = stream.Stream(output_notes)\n","\n","midi_stream.write('midi', fp=image_path)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
