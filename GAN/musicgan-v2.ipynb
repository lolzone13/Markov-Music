<<<<<<< HEAD
{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:47:14.308692Z","iopub.status.busy":"2023-05-03T13:47:14.308180Z","iopub.status.idle":"2023-05-03T13:47:14.314897Z","shell.execute_reply":"2023-05-03T13:47:14.313692Z","shell.execute_reply.started":"2023-05-03T13:47:14.308642Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","try:\n","    shutil.rmtree(\"generated_images\")\n","    os.mkdir(\"generated_images\")\n","except:\n","    os.mkdir(\"generated_images\")"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-03T13:47:14.316430Z","iopub.status.busy":"2023-05-03T13:47:14.316027Z","iopub.status.idle":"2023-05-03T13:47:23.437187Z","shell.execute_reply":"2023-05-03T13:47:23.435828Z","shell.execute_reply.started":"2023-05-03T13:47:14.316381Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from PIL import Image\n","import numpy as np\n","from MIDIConverter import MIDIConverter\n","from music21 import instrument, note, chord, stream, converter\n","import sys\n","from imageio import imwrite"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:47:23.476429Z","iopub.status.busy":"2023-05-03T13:47:23.476004Z","iopub.status.idle":"2023-05-03T13:55:41.384483Z","shell.execute_reply":"2023-05-03T13:55:41.383031Z","shell.execute_reply.started":"2023-05-03T13:47:23.476392Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2005 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=6, channel=None, data=b'Copyright \\xa9 2004 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2006 by Bernd Krueger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1998 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2007 by Bernd Krueger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2004 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2004 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n"]},{"ename":"UnidentifiedImageError","evalue":"cannot identify image file '/kaggle/input/classical-music-midi/liszt/liz_et6.mid'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/902949408.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcvt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidi2image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcvt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage2midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/3788743886.py\u001b[0m in \u001b[0;36mimage2midi\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimage2midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mim_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3281\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3283\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/kaggle/input/classical-music-midi/liszt/liz_et6.mid'"]}],"source":["# Generating Dataset\n","\n","\n","# os.makedirs(\"generated_images\")\n","cvt = MIDIConverter()\n","parent_path = \"/kaggle/input/classical-music-midi/mozart\"\n","\n","all_files = []\n","\n","for root, dirnames, filenames in os.walk(parent_path):\n","    for j in filenames:\n","        all_files.append(root + \"/\" + j)\n","\n","\n","for fname in all_files:\n","    try:\n","        cvt.midi2image(fname)\n","    except:\n","        pass\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:33.724192Z","iopub.status.busy":"2023-05-03T13:56:33.723781Z","iopub.status.idle":"2023-05-03T13:56:34.442907Z","shell.execute_reply":"2023-05-03T13:56:34.441414Z","shell.execute_reply.started":"2023-05-03T13:56:33.724157Z"},"trusted":true},"outputs":[],"source":["path = '/kaggle/working/generated_images'\n","os.getcwd()\n","img_list = os.listdir(path)\n","\n","\n","def image_data(img_list, path, length):\n","    pixels = []\n","    imgs = []    \n","    for img in img_list:\n","        if \"png\" in img:\n","            # quantized and dithered image\n","            img_arr = Image.open(path+'/'+img, 'r').convert('1') \n","            # normalize the pixel values\n","            pixel = np.array(img_arr.getdata()).astype('float32') / 255.0 \n","            # pad with zeros\n","            pixel = np.pad(pixel, (0, 106 * 106 - pixel.shape[0]), 'constant', constant_values=(0))\n","            # reshaping into 106 to 106\n","            pixels.append(pixel.reshape((106, 106, 1)))\n","            imgs.append(img_arr)\n","    return np.array(pixels), imgs\n","\n","\n","\n","\n","def show_image(pixels):\n","    array = np.array(pixels.reshape(106, 106), dtype=np.uint8)\n","    new_image = Image.fromarray(array)\n","    new_image.show()\n","\n","\n","# pixels, imgs = access_images(img_list, path, 200)\n","pixels, imgs = image_data(img_list, path, 200)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.445679Z","iopub.status.busy":"2023-05-03T13:56:34.445178Z","iopub.status.idle":"2023-05-03T13:56:34.454123Z","shell.execute_reply":"2023-05-03T13:56:34.452709Z","shell.execute_reply.started":"2023-05-03T13:56:34.445640Z"},"trusted":true},"outputs":[],"source":["from numpy import zeros\n","from numpy import ones\n","from numpy import vstack\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras.datasets.mnist import load_data\n","from keras.optimizers import Adam\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten, BatchNormalization\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import Dropout\n","from matplotlib import pyplot\n","from IPython.display import clear_output"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.456153Z","iopub.status.busy":"2023-05-03T13:56:34.455770Z","iopub.status.idle":"2023-05-03T13:56:34.474820Z","shell.execute_reply":"2023-05-03T13:56:34.473408Z","shell.execute_reply.started":"2023-05-03T13:56:34.456114Z"},"trusted":true},"outputs":[],"source":["\n","def define_discriminator(in_shape=(106, 106, 1)):\n","    \n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=in_shape))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(tf.keras.layers.Dropout(0.3))\n","\n","    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same'))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(tf.keras.layers.Dropout(0.3))\n","\n","    model.add(tf.keras.layers.Flatten())\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","    opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy',optimizer=opt, metrics=['accuracy'])\n","    \n","    \n","    return model\n","def define_generator(latent_dim):\n","    model = tf.keras.Sequential()\n","    n_nodes = 128 * 53 * 53\n","    model.add(tf.keras.layers.Dense(n_nodes, input_dim=latent_dim))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(Reshape((53, 53, 128)))\n","    model.add(tf.keras.layers.Dense(1024))\n","    model.add(tf.keras.layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same'))\n","    model.add(tf.keras.layers.Dense(1024))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(tf.keras.layers.Dense(1024))\n","    model.add(tf.keras.layers.Conv2D(1, (7, 7), padding='same', activation='sigmoid'))\n","    return model\n","\n","def define_gan(g_model, d_model):\n","    d_model.trainable = False\n","    model = tf.keras.Sequential()\n","    model.add(g_model)\n","    model.add(d_model)\n","    opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy', optimizer=opt)\n","    return model\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.477724Z","iopub.status.busy":"2023-05-03T13:56:34.477278Z","iopub.status.idle":"2023-05-03T13:56:34.491547Z","shell.execute_reply":"2023-05-03T13:56:34.490018Z","shell.execute_reply.started":"2023-05-03T13:56:34.477685Z"},"trusted":true},"outputs":[],"source":["\n","# Generate Real and Fake Samples to test the discriminator\n","\n","def generate_real_samples(dataset, n_samples):\n","    ix = randint(0, dataset.shape[0], n_samples)\n","    # Return X and y\n","    return dataset[ix], np.ones((n_samples, 1))\n","\n","def generate_fake_samples(g_model, latent_dim, n_samples):\n","    x_input = generate_latent_points(latent_dim, n_samples)\n","    X = g_model.predict(x_input)\n","    y = zeros((n_samples, 1))\n","    return X, y\n","\n","\n","def generate_latent_points(latent_dim, n_samples):\n","    # generate values from normal distribution of shape 106 x 106\n","    x_input = randn(latent_dim * n_samples).reshape(n_samples, latent_dim)\n","    return x_input\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.493837Z","iopub.status.busy":"2023-05-03T13:56:34.493423Z","iopub.status.idle":"2023-05-03T13:56:34.509209Z","shell.execute_reply":"2023-05-03T13:56:34.507803Z","shell.execute_reply.started":"2023-05-03T13:56:34.493737Z"},"trusted":true},"outputs":[],"source":["def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=35, n_batch=10):\n","    bat_per_epo = int(dataset.shape[0] / n_batch)\n","    half_batch = int(n_batch / 2)\n","    n_samples = 100\n","    for i in range(n_epochs):\n","        for j in range(bat_per_epo):\n","            \n","            X_real, y_real = generate_real_samples(dataset, half_batch)\n","            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n","            # get discriminator loss\n","            d_loss, _ = d_model.train_on_batch(X, y)\n","            # get generator loss\n","            g_loss = gan_model.train_on_batch(generate_latent_points(latent_dim, n_batch), ones((n_batch, 1)))\n","            print('>%d, %d/%d, d=%.3f, g=%.3f' %\n","                  (i+1, j+1, bat_per_epo, d_loss, g_loss))\n","        if (i+1) % 10 == 0:\n","            # evaluate performance of discriminator and generator\n","            X_real, y_real = generate_real_samples(dataset, n_samples)\n","\n","            _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n","\n","            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n","            _, acc_fake = d_model.evaluate(X_fake, y_fake, verbose=0)\n","            print('>Accuracy real: %.0f%%, fake: %.0f%%' %\n","                  (acc_real*100, acc_fake*100))\n","            filename = 'generator_model_%03d.h5' % (epoch + 1)\n","            g_model.save(filename)\n","            clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.511788Z","iopub.status.busy":"2023-05-03T13:56:34.510831Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 10s 10s/step\n",">1, 1/43, d=0.795, g=1.662\n","1/1 [==============================] - 9s 9s/step\n"]}],"source":["latent_dim = 100\n","d_model = define_discriminator()\n","g_model = define_generator(latent_dim)\n","gan_model = define_gan(g_model, d_model)\n","train(g_model, d_model, gan_model, np.array(pixels), latent_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.models import load_model\n","from numpy.random import randn\n","from matplotlib import pyplot\n","\n","\n","# Generating the Output\n","\n","def generate_latent_points(latent_dim, n_samples):\n","    x_input = randn(latent_dim * n_samples)\n","    x_input = x_input.reshape(n_samples, latent_dim)\n","    return x_input\n","\n","\n","model = g_model\n","# latent_points = generate_latent_points(latent_dim, 1)\n","# X = g_model.predict(latent_points)\n","# array = np.array(X.reshape(pixel_width, pixel_width), dtype=np.uint8)\n","# array *= 255\n","# new_image = Image.fromarray(array, 'L')\n","# new_image = new_image.save('/kaggle/working/test/composition.png')\n","\n","output_notes = []\n","\n","for i in range(10): \n","    latent_points = generate_latent_points(latent_dim, 1)\n","    X = g_model.predict(latent_points)\n","    array = np.array(X.reshape(pixel_width, pixel_width), dtype=np.uint8)\n","    array *= 255\n","    new_image = Image.fromarray(array, 'L')\n","    new_image = new_image.save('/kaggle/working/test/composition_{}.png'.format(i))\n","    output_notes+=cvt.image2midi('/kaggle/working/test/composition_{}.png'.format(i))\n","    \n","image_path = '/kaggle/working/composition.mid'\n","print(\"Output Notes: \", output_notes)\n","midi_stream = stream.Stream(output_notes)\n","\n","midi_stream.write('midi', fp=image_path)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
=======
{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:47:14.308692Z","iopub.status.busy":"2023-05-03T13:47:14.308180Z","iopub.status.idle":"2023-05-03T13:47:14.314897Z","shell.execute_reply":"2023-05-03T13:47:14.313692Z","shell.execute_reply.started":"2023-05-03T13:47:14.308642Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","try:\n","    shutil.rmtree(\"generated_images\")\n","    os.mkdir(\"generated_images\")\n","except:\n","    os.mkdir(\"generated_images\")"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-03T13:47:14.316430Z","iopub.status.busy":"2023-05-03T13:47:14.316027Z","iopub.status.idle":"2023-05-03T13:47:23.437187Z","shell.execute_reply":"2023-05-03T13:47:23.435828Z","shell.execute_reply.started":"2023-05-03T13:47:14.316381Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from PIL import Image\n","import numpy as np\n","from music21 import instrument, note, chord, stream, converter\n","import sys\n","from imageio import imwrite\n","from MIDIConverter import MIDIConverter\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:47:23.476429Z","iopub.status.busy":"2023-05-03T13:47:23.476004Z","iopub.status.idle":"2023-05-03T13:55:41.384483Z","shell.execute_reply":"2023-05-03T13:55:41.383031Z","shell.execute_reply.started":"2023-05-03T13:47:23.476392Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2005 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=6, channel=None, data=b'Copyright \\xa9 2004 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2006 by Bernd Krueger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1998 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2007 by Bernd Krueger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2004 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n","/opt/conda/lib/python3.7/site-packages/music21/midi/translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2004 by Bernd Kr\\xfcger'>; getting generic Instrument\n","  TranslateWarning)\n"]},{"ename":"UnidentifiedImageError","evalue":"cannot identify image file '/kaggle/input/classical-music-midi/liszt/liz_et6.mid'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/902949408.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcvt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidi2image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcvt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage2midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/3788743886.py\u001b[0m in \u001b[0;36mimage2midi\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimage2midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mim_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3281\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3283\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/kaggle/input/classical-music-midi/liszt/liz_et6.mid'"]}],"source":["# Generating Dataset\n","\n","\n","# os.makedirs(\"generated_images\")\n","cvt = MIDIConverter()\n","parent_path = \"/kaggle/input/classical-music-midi/mozart\"\n","\n","all_files = []\n","\n","for root, dirnames, filenames in os.walk(parent_path):\n","    for j in filenames:\n","        all_files.append(root + \"/\" + j)\n","\n","\n","for fname in all_files:\n","    try:\n","        cvt.midi2image(fname)\n","    except:\n","        pass\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pixel_width = 106"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:33.724192Z","iopub.status.busy":"2023-05-03T13:56:33.723781Z","iopub.status.idle":"2023-05-03T13:56:34.442907Z","shell.execute_reply":"2023-05-03T13:56:34.441414Z","shell.execute_reply.started":"2023-05-03T13:56:33.724157Z"},"trusted":true},"outputs":[],"source":["path = '/kaggle/working/generated_images'\n","os.getcwd()\n","img_list = os.listdir(path)\n","\n","\n","def image_data(img_list, path, length):\n","    pixels = []\n","    imgs = []    \n","    for img in img_list:\n","        if \"png\" in img:\n","            # quantized and dithered image\n","            img_arr = Image.open(path+'/'+img, 'r').convert('1') \n","            # normalize the pixel values\n","            pixel = np.array(img_arr.getdata()).astype('float32') / 255.0 \n","            # pad with zeros\n","            pixel = np.pad(pixel, (0, 106 * 106 - pixel.shape[0]), 'constant', constant_values=(0))\n","            # reshaping into 106 to 106\n","            pixels.append(pixel.reshape((106, 106, 1)))\n","            imgs.append(img_arr)\n","    return np.array(pixels), imgs\n","\n","\n","\n","\n","def show_image(pixels):\n","    array = np.array(pixels.reshape(106, 106), dtype=np.uint8)\n","    new_image = Image.fromarray(array)\n","    new_image.show()\n","\n","\n","# pixels, imgs = access_images(img_list, path, 200)\n","pixels, imgs = image_data(img_list, path, 200)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.445679Z","iopub.status.busy":"2023-05-03T13:56:34.445178Z","iopub.status.idle":"2023-05-03T13:56:34.454123Z","shell.execute_reply":"2023-05-03T13:56:34.452709Z","shell.execute_reply.started":"2023-05-03T13:56:34.445640Z"},"trusted":true},"outputs":[],"source":["from numpy import zeros\n","from numpy import ones\n","from numpy import vstack\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras.datasets.mnist import load_data\n","from keras.optimizers import Adam\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten, BatchNormalization\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import Dropout\n","from matplotlib import pyplot\n","from IPython.display import clear_output"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.456153Z","iopub.status.busy":"2023-05-03T13:56:34.455770Z","iopub.status.idle":"2023-05-03T13:56:34.474820Z","shell.execute_reply":"2023-05-03T13:56:34.473408Z","shell.execute_reply.started":"2023-05-03T13:56:34.456114Z"},"trusted":true},"outputs":[],"source":["\n","def define_discriminator(in_shape=(106, 106, 1)):\n","    \n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=in_shape))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(tf.keras.layers.Dropout(0.3))\n","\n","    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same'))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(tf.keras.layers.Dropout(0.3))\n","\n","    model.add(tf.keras.layers.Flatten())\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","    opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy',optimizer=opt, metrics=['accuracy'])\n","    \n","    \n","    return model\n","def define_generator(latent_dim):\n","    model = tf.keras.Sequential()\n","    n_nodes = 128 * 53 * 53\n","    model.add(tf.keras.layers.Dense(n_nodes, input_dim=latent_dim))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(Reshape((53, 53, 128)))\n","    model.add(tf.keras.layers.Dense(1024))\n","    model.add(tf.keras.layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same'))\n","    model.add(tf.keras.layers.Dense(1024))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(tf.keras.layers.Dense(1024))\n","    model.add(tf.keras.layers.Conv2D(1, (7, 7), padding='same', activation='sigmoid'))\n","    return model\n","\n","def define_gan(g_model, d_model):\n","    d_model.trainable = False\n","    model = tf.keras.Sequential()\n","    model.add(g_model)\n","    model.add(d_model)\n","    opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy', optimizer=opt)\n","    return model\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.477724Z","iopub.status.busy":"2023-05-03T13:56:34.477278Z","iopub.status.idle":"2023-05-03T13:56:34.491547Z","shell.execute_reply":"2023-05-03T13:56:34.490018Z","shell.execute_reply.started":"2023-05-03T13:56:34.477685Z"},"trusted":true},"outputs":[],"source":["\n","# Generate Real and Fake Samples to test the discriminator\n","\n","def generate_real_samples(dataset, n_samples):\n","    ix = randint(0, dataset.shape[0], n_samples)\n","    # Return X and y\n","    return dataset[ix], np.ones((n_samples, 1))\n","\n","def generate_fake_samples(g_model, latent_dim, n_samples):\n","    x_input = generate_latent_points(latent_dim, n_samples)\n","    X = g_model.predict(x_input)\n","    y = zeros((n_samples, 1))\n","    return X, y\n","\n","\n","def generate_latent_points(latent_dim, n_samples):\n","    # generate values from normal distribution of shape 106 x 106\n","    x_input = randn(latent_dim * n_samples).reshape(n_samples, latent_dim)\n","    return x_input\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.493837Z","iopub.status.busy":"2023-05-03T13:56:34.493423Z","iopub.status.idle":"2023-05-03T13:56:34.509209Z","shell.execute_reply":"2023-05-03T13:56:34.507803Z","shell.execute_reply.started":"2023-05-03T13:56:34.493737Z"},"trusted":true},"outputs":[],"source":["def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=35, n_batch=10):\n","    bat_per_epo = int(dataset.shape[0] / n_batch)\n","    half_batch = int(n_batch / 2)\n","    n_samples = 100\n","    for i in range(n_epochs):\n","        for j in range(bat_per_epo):\n","            \n","            X_real, y_real = generate_real_samples(dataset, half_batch)\n","            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n","            # get discriminator loss\n","            d_loss, _ = d_model.train_on_batch(X, y)\n","            # get generator loss\n","            g_loss = gan_model.train_on_batch(generate_latent_points(latent_dim, n_batch), ones((n_batch, 1)))\n","            print('>%d, %d/%d, d=%.3f, g=%.3f' %\n","                  (i+1, j+1, bat_per_epo, d_loss, g_loss))\n","        if (i+1) % 10 == 0:\n","            # evaluate performance of discriminator and generator\n","            X_real, y_real = generate_real_samples(dataset, n_samples)\n","\n","            _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n","\n","            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n","            _, acc_fake = d_model.evaluate(X_fake, y_fake, verbose=0)\n","            print('>Accuracy real: %.0f%%, fake: %.0f%%' %\n","                  (acc_real*100, acc_fake*100))\n","            filename = 'generator_model_%03d.h5' % (i + 1)\n","            g_model.save(filename)\n","            clear_output()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T13:56:34.511788Z","iopub.status.busy":"2023-05-03T13:56:34.510831Z","iopub.status.idle":"2023-05-03T13:59:01.638060Z","shell.execute_reply":"2023-05-03T13:59:01.636656Z","shell.execute_reply.started":"2023-05-03T13:56:34.511737Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 10s 10s/step\n",">1, 1/43, d=0.795, g=1.662\n","1/1 [==============================] - 9s 9s/step\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2778017754.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgan_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/3696375576.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# get generator loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             print('>%d, %d/%d, d=%.3f, g=%.3f' %\n\u001b[1;32m     16\u001b[0m                   (i+1, j+1, bat_per_epo, d_loss, g_loss))\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2476\u001b[0m             )\n\u001b[1;32m   2477\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2478\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["latent_dim = 100\n","d_model = define_discriminator()\n","g_model = define_generator(latent_dim)\n","gan_model = define_gan(g_model, d_model)\n","train(g_model, d_model, gan_model, np.array(pixels), latent_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-03T13:59:01.639405Z","iopub.status.idle":"2023-05-03T13:59:01.640191Z","shell.execute_reply":"2023-05-03T13:59:01.639962Z","shell.execute_reply.started":"2023-05-03T13:59:01.639937Z"},"trusted":true},"outputs":[],"source":["from tf.keras.models import load_model\n","from numpy.random import randn\n","from matplotlib import pyplot\n","\n","\n","# Generating the Output\n","\n","def generate_latent_points(latent_dim, n_samples):\n","    x_input = randn(latent_dim * n_samples)\n","    x_input = x_input.reshape(n_samples, latent_dim)\n","    return x_input\n","\n","\n","model = g_model\n","# latent_points = generate_latent_points(latent_dim, 1)\n","# X = g_model.predict(latent_points)\n","# array = np.array(X.reshape(pixel_width, pixel_width), dtype=np.uint8)\n","# array *= 255\n","# new_image = Image.fromarray(array, 'L')\n","# new_image = new_image.save('/kaggle/working/test/composition.png')\n","\n","output_notes = []\n","\n","for i in range(10): \n","    latent_points = generate_latent_points(latent_dim, 1)\n","    X = g_model.predict(latent_points)\n","    array = np.array(X.reshape(pixel_width, pixel_width), dtype=np.uint8)\n","    array *= 255\n","    new_image = Image.fromarray(array, 'L')\n","    new_image = new_image.save('/kaggle/working/test/composition_{}.png'.format(i))\n","    output_notes+=cvt.image2midi('/kaggle/working/test/composition_{}.png'.format(i))\n","    \n","image_path = '/kaggle/working/composition.mid'\n","print(\"Output Notes: \", output_notes)\n","midi_stream = stream.Stream(output_notes)\n","\n","midi_stream.write('midi', fp=image_path)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
>>>>>>> 2aebf1fe4ba4e368b1c457481c34bed7664fd31e
